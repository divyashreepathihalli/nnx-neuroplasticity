#!/usr/bin/env python3
"""
ARC Real Puzzle Test - Using Actual ARC Examples

This test uses real ARC puzzle examples with scaling transformation pattern.
"""

import jax
import jax.numpy as jnp
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors
from flax import linen as nn

from utils import setup_random_seed, print_training_header, print_training_step, print_final_results

# Set up random seed
setup_random_seed(42)

# ARC Color palette
ARC_COLORS = {
    0: 'white',      # Background
    1: 'red',        # Red
    2: 'blue',       # Blue  
    3: 'green',      # Green
    4: 'yellow',     # Yellow
    5: 'purple',     # Purple
    6: 'orange',     # Orange
    7: 'magenta',    # Magenta
    8: 'lightblue',  # Light Blue
    9: 'lightgreen'  # Light Green
}

class ARCScalingSolver:
    """
    An ARC solver specifically for scaling transformations.
    """
    
    def __init__(self, grid_size=6, num_patterns=4, num_colors=10):
        self.grid_size = grid_size
        self.num_patterns = num_patterns
        self.num_colors = num_colors
        
        # Plasticity variables
        self.pattern_memory = np.zeros((num_patterns, 6 * 6 * num_colors))  # Max size for 6x6
        self.attention_weights = np.ones(num_patterns)
        self.scaling_rules = np.zeros((num_patterns, 4))  # [scale_factor, input_size, output_size]
        self.color_mapping = np.zeros((num_patterns, num_colors, num_colors))
        self.plasticity_rate = 0.2
        
        # Learning history
        self.learning_history = []
        self.pattern_usage = np.zeros(num_patterns)
    
    def encode_grid(self, grid):
        """Encode colored grid to pattern representation."""
        grid_size = grid.shape[0]
        encoded = np.zeros((grid_size, grid_size, self.num_colors))
        for i in range(grid_size):
            for j in range(grid_size):
                color_idx = grid[i, j]
                if color_idx < self.num_colors:
                    encoded[i, j, color_idx] = 1
        return encoded.reshape(-1)
    
    def find_similar_pattern(self, input_pattern):
        """Find most similar stored pattern with attention weighting."""
        similarities = np.dot(self.pattern_memory, input_pattern)
        weighted_similarities = similarities * self.attention_weights
        most_similar_idx = np.argmax(weighted_similarities)
        return most_similar_idx, weighted_similarities[most_similar_idx]
    
    def update_pattern_memory(self, input_pattern, pattern_idx):
        """Update pattern memory with Hebbian learning."""
        current_memory = self.pattern_memory[pattern_idx]
        update = self.plasticity_rate * input_pattern
        decay = 0.9
        self.pattern_memory[pattern_idx] = decay * current_memory + update
        
        # Update attention weights based on usage
        self.attention_weights[pattern_idx] += 0.15
        self.pattern_usage[pattern_idx] += 1
        
        # Normalize attention weights
        self.attention_weights = self.attention_weights / np.sum(self.attention_weights)
    
    def learn_scaling_transformation(self, input_grid, output_grid):
        """Learn scaling transformation rule from input-output pair."""
        input_pattern = self.encode_grid(input_grid)
        output_pattern = self.encode_grid(output_grid)
        
        # Find most similar pattern
        pattern_idx, similarity = self.find_similar_pattern(input_pattern)
        
        # Update pattern memory
        self.update_pattern_memory(input_pattern, pattern_idx)
        
        # Learn scaling rule
        input_size = input_grid.shape[0]
        output_size = output_grid.shape[0]
        scale_factor = output_size // input_size
        
        self.scaling_rules[pattern_idx] = [scale_factor, input_size, output_size]
        
        # Learn color mapping (identity mapping for scaling)
        for i in range(self.num_colors):
            self.color_mapping[pattern_idx, i, i] += 0.2
        
        # Record learning event
        self.learning_history.append({
            'pattern_idx': pattern_idx,
            'similarity': similarity,
            'input_grid': input_grid.copy(),
            'output_grid': output_grid.copy(),
            'scale_factor': scale_factor
        })
        
        return pattern_idx, similarity, scale_factor
    
    def apply_scaling_transformation(self, input_grid):
        """Apply learned scaling transformation to input grid."""
        input_pattern = self.encode_grid(input_grid)
        
        # Find most similar pattern
        pattern_idx, similarity = self.find_similar_pattern(input_pattern)
        
        # Get scaling rule
        scale_factor, input_size, output_size = self.scaling_rules[pattern_idx]
        
        # Apply scaling transformation
        output_grid = np.zeros((output_size, output_size), dtype=int)
        
        for i in range(input_size):
            for j in range(input_size):
                # Get color from input
                color = input_grid[i, j]
                
                # Scale up this cell
                for di in range(scale_factor):
                    for dj in range(scale_factor):
                        output_i = i * scale_factor + di
                        output_j = j * scale_factor + dj
                        if output_i < output_size and output_j < output_size:
                            output_grid[output_i, output_j] = color
        
        return output_grid, pattern_idx, similarity, scale_factor
    
    def get_plasticity_metrics(self):
        """Get plasticity metrics."""
        return {
            'pattern_memory_activity': np.mean(self.pattern_memory),
            'attention_weights': np.mean(self.attention_weights),
            'scaling_rules': np.mean(self.scaling_rules),
            'color_mapping_activity': np.mean(self.color_mapping),
            'pattern_usage_diversity': np.std(self.pattern_usage),
            'memory_diversity': np.std(self.pattern_memory)
        }


def create_real_arc_problem():
    """Create the real ARC problem based on the provided examples."""
    
    # Example 1: 2x2 to 6x6 scaling
    example1_input = np.array([
        [8, 7],  # Light blue, magenta
        [7, 4]   # Magenta, yellow
    ])
    
    example1_output = np.array([
        [8, 8, 8, 7, 7, 7],
        [8, 8, 8, 7, 7, 7],
        [8, 8, 8, 7, 7, 7],
        [7, 7, 7, 4, 4, 4],
        [7, 7, 7, 4, 4, 4],
        [7, 7, 7, 4, 4, 4]
    ])
    
    # Example 2: 2x2 to 6x6 scaling (different colors)
    example2_input = np.array([
        [6, 1],  # Orange, red
        [4, 3]   # Yellow, green
    ])
    
    example2_output = np.array([
        [6, 6, 6, 1, 1, 1],
        [6, 6, 6, 1, 1, 1],
        [6, 6, 6, 1, 1, 1],
        [4, 4, 4, 3, 3, 3],
        [4, 4, 4, 3, 3, 3],
        [4, 4, 4, 3, 3, 3]
    ])
    
    # Test question: 2x2 to 6x6 scaling
    test_input = np.array([
        [3, 5],  # Green, purple
        [2, 1]   # Blue, red
    ])
    
    # Expected answer (3x scaling)
    expected_output = np.array([
        [3, 3, 3, 5, 5, 5],
        [3, 3, 3, 5, 5, 5],
        [3, 3, 3, 5, 5, 5],
        [2, 2, 2, 1, 1, 1],
        [2, 2, 2, 1, 1, 1],
        [2, 2, 2, 1, 1, 1]
    ])
    
    return {
        'examples': [
            (example1_input, example1_output, "Example 1"),
            (example2_input, example2_output, "Example 2")
        ],
        'test': (test_input, expected_output, "Test Question")
    }


def visualize_arc_problem(problem_data):
    """Visualize the ARC problem with examples and test."""
    examples = problem_data['examples']
    test_input, expected_output, test_name = problem_data['test']
    
    # Create figure with examples and test
    fig, axes = plt.subplots(2, 3, figsize=(18, 12))
    fig.suptitle('Real ARC Problem: Scaling Transformation', fontsize=16)
    
    # Create color map
    colors = list(ARC_COLORS.values())[:10]
    cmap = mcolors.ListedColormap(colors)
    
    # Plot examples
    for i, (input_grid, output_grid, title) in enumerate(examples):
        # Input
        im1 = axes[0, i].imshow(input_grid, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
        axes[0, i].set_title(f'{title} - Input ({input_grid.shape[0]}x{input_grid.shape[1]})')
        axes[0, i].set_xticks([])
        axes[0, i].set_yticks([])
        
        # Output
        im2 = axes[1, i].imshow(output_grid, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
        axes[1, i].set_title(f'{title} - Output ({output_grid.shape[0]}x{output_grid.shape[1]})')
        axes[1, i].set_xticks([])
        axes[1, i].set_yticks([])
    
    # Plot test question
    im3 = axes[0, 2].imshow(test_input, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
    axes[0, 2].set_title('Test Question - Input (2x2)')
    axes[0, 2].set_xticks([])
    axes[0, 2].set_yticks([])
    
    im4 = axes[1, 2].imshow(expected_output, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
    axes[1, 2].set_title('Test Question - Expected Output (6x6)')
    axes[1, 2].set_xticks([])
    axes[1, 2].set_yticks([])
    
    plt.tight_layout()
    plt.show()


def visualize_prediction(test_input, predicted_output, expected_output, accuracy):
    """Visualize the prediction result."""
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Create color map
    colors = list(ARC_COLORS.values())[:10]
    cmap = mcolors.ListedColormap(colors)
    
    # Test input
    im1 = axes[0].imshow(test_input, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
    axes[0].set_title('Test Input (2x2)')
    axes[0].set_xticks([])
    axes[0].set_yticks([])
    
    # Predicted output
    im2 = axes[1].imshow(predicted_output, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
    axes[1].set_title(f'Predicted Output (6x6)\nAccuracy: {accuracy:.3f}')
    axes[1].set_xticks([])
    axes[1].set_yticks([])
    
    # Expected output
    im3 = axes[2].imshow(expected_output, cmap=cmap, vmin=0, vmax=9, interpolation='nearest')
    axes[2].set_title('Expected Output (6x6)')
    axes[2].set_xticks([])
    axes[2].set_yticks([])
    
    plt.suptitle('ARC Scaling Transformation Prediction')
    plt.tight_layout()
    plt.show()


def main():
    """Main function demonstrating real ARC puzzle solving."""
    print("ðŸ§© Real ARC Puzzle Test - Scaling Transformation")
    print("=" * 60)
    print("Based on actual ARC puzzle examples")
    print()
    
    # Create real ARC problem
    print("ðŸ“Š Creating real ARC problem...")
    problem_data = create_real_arc_problem()
    examples = problem_data['examples']
    test_input, expected_output, test_name = problem_data['test']
    
    print(f"Created problem with {len(examples)} examples and 1 test question")
    
    # Visualize the problem
    print("\nðŸŽ¯ Real ARC Problem:")
    visualize_arc_problem(problem_data)
    
    # Create solver
    solver = ARCScalingSolver(grid_size=6, num_patterns=4, num_colors=10)
    
    print("âœ… ARC Scaling Solver initialized")
    print("ðŸ“ˆ Learning scaling transformations from examples...")
    print_training_header()
    
    # Learn from examples
    for i, (input_grid, output_grid, example_name) in enumerate(examples):
        # Learn transformation
        pattern_idx, similarity, scale_factor = solver.learn_scaling_transformation(input_grid, output_grid)
        
        # Get plasticity metrics
        metrics = solver.get_plasticity_metrics()
        metrics_float = {k: float(v) for k, v in metrics.items()}
        
        print_training_step(i, similarity, metrics_float)
        print(f"   ðŸ“Š Learned from {example_name} using pattern {pattern_idx} (scale factor: {scale_factor})")
    
    print_final_results(similarity, metrics_float)
    
    # Predict test output
    print("\nðŸŽ¯ Predicting test output...")
    predicted_output, pattern_idx, similarity, scale_factor = solver.apply_scaling_transformation(test_input)
    
    # Calculate accuracy
    accuracy = np.mean(expected_output == predicted_output)
    
    print(f"ðŸ“Š Prediction Results:")
    print(f"   - Pattern used: {pattern_idx}")
    print(f"   - Similarity: {similarity:.3f}")
    print(f"   - Scale factor: {scale_factor}")
    print(f"   - Accuracy: {accuracy:.3f}")
    
    # Visualize prediction
    visualize_prediction(test_input, predicted_output, expected_output, accuracy)
    
    # Show plasticity metrics
    print("\nðŸ§  Final Plasticity Metrics:")
    final_metrics = solver.get_plasticity_metrics()
    for key, value in final_metrics.items():
        print(f"   - {key.replace('_', ' ').title()}: {value:.6f}")
    
    print("\nðŸ’¡ Key Learning Insights:")
    print("   â€¢ Scaling Recognition: Identified 3x scaling transformation")
    print("   â€¢ Pattern Generalization: Applied scaling to new colors")
    print("   â€¢ Neuroplasticity: Adapted pattern memory based on examples")
    print("   â€¢ Spatial Transformation: Learned pixel replication rule")
    
    print("\nðŸŽ¨ ARC Scaling-Specific Features:")
    print("   â€¢ Example Learning: Extracted scaling rules from pairs")
    print("   â€¢ Pattern Generalization: Applied scaling to unseen colors")
    print("   â€¢ Color Preservation: Maintained original colors in scaling")
    print("   â€¢ Spatial Invariance: Applied scaling regardless of colors")
    
    print("\nâœ… Real ARC Puzzle Test completed!")
    print("ðŸ’­ This demonstrates how neuroplasticity could enable")
    print("   learning of complex spatial transformations!")


if __name__ == "__main__":
    main() 